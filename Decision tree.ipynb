{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pydot\n",
    "from io import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "from Final_dm_tool import data_prep \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_feature_importance(dm_model, feature_names, n_to_display=20):\n",
    "    # grab feature importances from the model\n",
    "    importances = dm_model.feature_importances_\n",
    "    \n",
    "    # sort them out in descending order\n",
    "    indices = np.argsort(importances)\n",
    "    indices = np.flip(indices, axis=0)\n",
    "\n",
    "    # limit to 20 features, you can leave this out to print out everything\n",
    "    indices = indices[:n_to_display]\n",
    "\n",
    "    print(\"\\n\\n*********** Feature Importances ************\\n\")   \n",
    "    for i in indices:\n",
    "        print(f\"{feature_names[i]:<35}:{importances[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_decision_tree(dm_model, feature_names, save_name):\n",
    "    dotfile = StringIO()\n",
    "    export_graphviz(dm_model, out_file=dotfile, feature_names=feature_names, filled=True, rounded=True)\n",
    "    graph = pydot.graph_from_dot_data(dotfile.getvalue())\n",
    "    graph[0].write_png(save_name) # saved in the following file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_of_tree(model):\n",
    "\n",
    "\n",
    "# Using those arrays, we can parse the tree structure:\n",
    "\n",
    "    n_nodes = model.tree_.node_count\n",
    "    children_left = model.tree_.children_left\n",
    "    children_right = model.tree_.children_right\n",
    "    feature = model.tree_.feature\n",
    "    threshold = model.tree_.threshold\n",
    "\n",
    "\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "        # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "    \n",
    "    \n",
    "    # Calculate decision node\n",
    "    decision_node_number = 0\n",
    "    leaf_node_number = 0\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            leaf_node_number = leaf_node_number + 1\n",
    "        else:\n",
    "            decision_node_number = decision_node_number + 1\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"\\n\\n*********** Size of decision tree ************\\n\") \n",
    "    print(\"The binary tree structure has %s nodes and has \" \"the following tree structure:\" % n_nodes)\n",
    "    print(\"The tree has %s decision nodes.\" % decision_node_number)\n",
    "    print(\"The tree has %s leaf nodes.\" % leaf_node_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2903: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "# preprocessing step\n",
    "df = data_prep()\n",
    "\n",
    "# target/input split\n",
    "y = df['IsBadBuy']\n",
    "X = df.drop(['IsBadBuy'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7511, 125)\n",
      "(3219, 125)\n",
      "(7511,)\n",
      "(3219,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\conda\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# setting random state\n",
    "# .as_matrix removed replaced with .values\n",
    "# train test 70 / 30 percent\n",
    "rs = 10\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.3, stratify=y, random_state=rs)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*********** Evaluation of the decision tree ************\n",
      "\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.7496116806461635\n",
      "\n",
      "\n",
      "*********** Confusion Matrix ************\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75      1609\n",
      "           1       0.75      0.74      0.75      1610\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      3219\n",
      "   macro avg       0.75      0.75      0.75      3219\n",
      "weighted avg       0.75      0.75      0.75      3219\n",
      "\n",
      "\n",
      "\n",
      "*********** Feature Importances ************\n",
      "\n",
      "Auction_ADESA                      :0.19951016019947423\n",
      "MMRCurrentAuctionAveragePrice      :0.08850121619510157\n",
      "VehOdo                             :0.05467146361906708\n",
      "VehBCost                           :0.0538048384103142\n",
      "MMRCurrentRetailRatio              :0.04000160585099367\n",
      "VNST_OK                            :0.036412515793597014\n",
      "WarrantyCost                       :0.032699127207786054\n",
      "MMRCurrentRetailCleanPrice         :0.03249131031610065\n",
      "MMRAcquisitionAuctionAveragePrice  :0.02796893939991498\n",
      "MMRAcquisitionAuctionCleanPrice    :0.02766899672875254\n",
      "MMRAcquisitionRetailAveragePrice   :0.027664009051721023\n",
      "MMRAcquisitonRetailCleanPrice      :0.02742412015087629\n",
      "VNST_CO                            :0.02603726183750516\n",
      "Auction_OTHER                      :0.019547871083264445\n",
      "MMRCurrentAuctionCleanPrice        :0.016177330077786628\n",
      "VNST_AZ                            :0.0161641404607167\n",
      "VNST_PA                            :0.014729430579449318\n",
      "Auction_MANHEIM                    :0.01471069884735225\n",
      "VNST_CA                            :0.014539973652830477\n",
      "MMRCurrentRetailAveragePrice       :0.012284708068352272\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "The binary tree structure has 1967 nodes and has the following tree structure:\n",
      "The tree has 983 decision nodes.\n",
      "The tree has 984 leaf nodes.\n",
      "\n",
      "\n",
      "*********** Size of default decision tree on test set ************\n",
      "\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "The binary tree structure has 883 nodes and has the following tree structure:\n",
      "The tree has 441 decision nodes.\n",
      "The tree has 442 leaf nodes.\n"
     ]
    }
   ],
   "source": [
    "# simple decision tree training with default setting\n",
    "model = DecisionTreeClassifier(random_state=rs)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# decision tree evaluation\n",
    "print(\"\\n\\n*********** Evaluation of the decision tree ************\\n\") \n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n\\n*********** Confusion Matrix ************\\n\") \n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "analyse_feature_importance(model, X.columns, 20)\n",
    "\n",
    "#visualising the model\n",
    "visualize_decision_tree(model, X.columns, \"default.png\")\n",
    "\n",
    "#Size of decision tree model\n",
    "print(\"\\n\\n*********** Size of decision tree ************\\n\") \n",
    "size_of_tree(model)\n",
    "\n",
    "#**************Fit model in test set*******************\n",
    "model.fit(X_test,y_test)\n",
    "#visualising the model\n",
    "visualize_decision_tree(model, X.columns, \"default_val_data.png\")\n",
    "\n",
    "#Size of decision tree model\n",
    "print(\"\\n\\n*********** Size of default decision tree on test set ************\\n\") \n",
    "size_of_tree(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Decition Tree model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*********** Evaluation of the decision tree ************\n",
      "\n",
      "Train accuracy: 0.75902010384769\n",
      "Test accuracy: 0.7567567567567568\n",
      "\n",
      "\n",
      "*********** Confusion Matrix ************\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.77      1609\n",
      "           1       0.80      0.68      0.74      1610\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      3219\n",
      "   macro avg       0.76      0.76      0.76      3219\n",
      "weighted avg       0.76      0.76      0.76      3219\n",
      "\n",
      "\n",
      "\n",
      "*********** Feature Importances ************\n",
      "\n",
      "Auction_ADESA                      :0.571435214578175\n",
      "MMRCurrentAuctionAveragePrice      :0.1454371788211704\n",
      "VNST_OK                            :0.09192443745447534\n",
      "VNST_CO                            :0.051861359005029174\n",
      "VNST_AZ                            :0.03242171935598875\n",
      "VNST_PA                            :0.029128640102322405\n",
      "Auction_OTHER                      :0.02742613108261397\n",
      "VehBCost                           :0.025783852802885004\n",
      "VNST_CA                            :0.015410298161252467\n",
      "VNST_TX                            :0.004722860655972494\n",
      "MMRCurrentRetailRatio              :0.004448307980114939\n",
      "Make_LINCOLN                       :0.0\n",
      "Make_LEXUS                         :0.0\n",
      "Make_JEEP                          :0.0\n",
      "Make_KIA                           :0.0\n",
      "Make_MERCURY                       :0.0\n",
      "Make_ISUZU                         :0.0\n",
      "Make_INFINITI                      :0.0\n",
      "Make_HYUNDAI                       :0.0\n",
      "Make_HONDA                         :0.0\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "The binary tree structure has 23 nodes and has the following tree structure:\n",
      "The tree has 11 decision nodes.\n",
      "The tree has 12 leaf nodes.\n",
      "\n",
      "\n",
      "*********** Size of default decision tree on test set ************\n",
      "\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "The binary tree structure has 25 nodes and has the following tree structure:\n",
      "The tree has 12 decision nodes.\n",
      "The tree has 13 leaf nodes.\n"
     ]
    }
   ],
   "source": [
    "#retrain with a small max_depth limit 5\n",
    "model_2 = DecisionTreeClassifier(max_depth=5, random_state=rs, )\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "# decision tree evaluation\n",
    "print(\"\\n\\n*********** Evaluation of the decision tree ************\\n\") \n",
    "print(\"Train accuracy:\", model_2.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model_2.score(X_test, y_test))\n",
    "\n",
    "#confusoin matrix\n",
    "print(\"\\n\\n*********** Confusion Matrix ************\\n\") \n",
    "y_pred = model_2.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "analyse_feature_importance(model_2, X.columns, 20)\n",
    "\n",
    "#visualising the model\n",
    "visualize_decision_tree(model_2, X.columns, \"second_tree.png\")\n",
    "\n",
    "#Size of decision tree model\n",
    "size_of_tree(model_2)\n",
    "\n",
    "#**************Fit model in test set*******************\n",
    "model_2.fit(X_test,y_test)\n",
    "#visualising the model\n",
    "visualize_decision_tree(model_2, X.columns, \"secondTree_val_data.png\")\n",
    "\n",
    "#Size of decision tree model\n",
    "print(\"\\n\\n*********** Size of default decision tree on test set ************\\n\") \n",
    "size_of_tree(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the performance of model with different complexity level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEXCAYAAABcRGizAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XeYVOXZx/HvLVWNIgg2UEBEBSUBXMESxQ5WJJZgi51YsCUmWIgaiIrRxI4NUUx8VURRorEgSlQUYZHepIjSRBBEECm73O8fzxl3WGZ3hmVnz+zu73Ndc82ZM+fM3MwO556nm7sjIiJSmm3iDkBERHKfkoWIiKSlZCEiImkpWYiISFpKFiIikpaShYiIpKVkISIiaSlZiIhIWkoWIiKSVs24AygvDRs29GbNmsUdhohIpTJu3Lhl7t4o3XFVJlk0a9aM/Pz8uMMQEalUzOyrTI5TNZSIiKSlZCEiImkpWYiISFpKFiIikpaShYiIpKVkISIiaSlZiIhUYu6wenX230fJQkSkkpoxAzp3hu7ds/9eShYiIpXMqlXw5z9DmzYwZgx06RJKGNlUZUZwi4hUde7wwgtw442weDFceincdRfsskv23zurJQsz62JmM81stpndlOL5pmY2wswmmdlIM2uS9NyFZjYrul2YzThFRHLdpEnQqROcdx40bgyjR8OAARWTKCCLycLMagCPAicCrYFzzKx1scPuA55z918CfYC7o3MbALcDHYEOwO1mVj9bsYqI5Krvv4drr4V27WDaNHjySfjsM+jYsWLjyGbJogMw293nuvt64EWga7FjWgMjou0Pkp7vDAx39+XuvgIYDnTJYqwiIjll40YYOBD23RcefRSuuAK++AIuvxy2iaG1OZtv2RiYn/R4QbQv2UTgjGi7G7CDme2c4bkiIlVSfj4cemhok2jZMjx+9FFo0CC+mLKZLCzFvuLt9TcCncxsPNAJWAgUZHguZtbDzPLNLH/p0qVbG6+ISKyWLYMePaBDB/jqK3juOfj441AFFbdsJosFwJ5Jj5sAi5IPcPdF7v4bd28H3BrtW5nJudGxT7p7nrvnNWqUdu0OEZGcVFgI/fuHKqeBA+GGG0KV0wUXgKX66RyDbCaLsUBLM2tuZrWB7sCw5APMrKGZJWK4GRgYbb8DnGBm9aOG7ROifSIiVcqoUZCXB1dfHUoQEyfCP/4BO+4Yd2SbylqycPcCoCfhIj8dGOzuU82sj5mdFh12FDDTzL4AdgXujM5dDvQlJJyxQJ9on4hIlTB+PJx1Fvz61/Ddd/Dyy/Dee3DAAXFHlpp5tof9VZC8vDzXsqoiksvc4cMP4e674Z13QunhuuugVy/Yfvt4YjKzce6el+44jeAWEckyd3jzzTDa+tNPw0C6u+6Cq66CevXiji4zShYiIllSUACDB0O/fjB5MjRtCo88ApdcAttuG3d0W0bJQkSknK1dC4MGwd//DnPnQqtW4fE550CtWnFHVzZKFiIi5WTVKnj8cfjnP+Gbb+Dgg0PPptNOi2fUdXlSshAR2UrLlsFDD8HDD4e5nI49Fv79bzjmmNwZJ7G1lCxERMpo/vxQcnjqKVizBk4/HW6+OYzArmqULEREttCqVXDbbWG+po0bw7ThvXpB6+LzalchShYiIlvgtdfgmmtg4cIw0d+tt0KzZnFHlX2VvMlFRKRizJ8fqpm6dYP69cM0HU89VT0SBShZiIiUqqAA7r8/dH99993QHXbcuDCFeHWiaigRkRLk54cpw8ePh5NOCm0U1aUkUZxKFiIixfzwQ5izqWPHMF7i5ZfhjTeqb6IAlSxERH7mDkOHhgbsxYvD3E133ll55m/KJpUsREQIK9OddhqccQY0ahQm/HvkESWKBCULEanWCgrCwLrWreH99+G++0JbRceOcUeWW1QNJSLV1pgx8Pvfw4QJcPLJoQG7adO4o8pNKlmISLXz/fehXeKQQ+Dbb2HIEPjPf5QoSqNkISLVxvr18MAD0KJFKEX07AnTp4d2iqoy4V+2KFmISJXnDi+9FAbW3XADtG8fBtY99FBY2lTSU7IQkSrtww9DY3X37mGd67ffDiOx27WLO7LKRclCRKqk6dOha1fo1AkWLYJnngkjsTt3VpVTWShZiEiV8s03cMUV0KYNfPAB3HUXfPEFXHQR1KgRd3SVl7rOikiVsHp1GC9x772wbl0Yff2Xv4QBdrL1lCxEpFIrKICBA+H220Op4swzQ2miZcu4I6talCxEpFJyD5P79eoV2icOPxxefbX6TR1eUdRmISKVztixcNRRYS6nwsKQJD76SIkim5QsRKTS2LgRbrkFOnSAGTOgf3+YMiWsXqceTtmlaigRqRRWrYILLoDXX4fLLoN//hN22CHuqKoPJQsRyXnz5oUqp2nTwqjrnj1VkqhoShYiktM+/DDM3VRQAG+9BccfH3dE1ZPaLEQkZz39NBx3HDRoAJ99pkQRJyULEck5BQVw/fWhbeLoo0Oi2HffuKOq3pQsRCSnfP99WIjowQdDwnjzTdhpp7ijErVZiEjO+OILOPVU+PJLGDAALr007ogkQclCRHLC8OFw9tlQsyaMGAFHHBF3RJJM1VAiEit3ePhhOPFE2HPPMDpbiSL3KFmISGzWr4ff/x6uvTa0U4waBc2axR2VpKJkISKxWLYsdIV96im4+WYYOlQjsnOZ2ixEpMJNmRIashcvhuefh3PPjTsiSSerJQsz62JmM81stpndlOL5vczsAzMbb2aTzOykaH8zM/vJzCZEt8ezGaeIVJxhw8LssOvWhdHZShSVQ9ZKFmZWA3gUOB5YAIw1s2HuPi3psN7AYHd/zMxaA/8FmkXPzXH3ttmKT0Qq1sqVcOutYabYgw6C116Dxo3jjkoylc2SRQdgtrvPdff1wItA12LHOLBjtF0PWJTFeEQkBu4wZAi0ahUSRc+e8L//KVFUNtlMFo2B+UmPF0T7kt0BnG9mCwilimuSnmseVU/9z8xSdqQzsx5mlm9m+UuXLi3H0EWkPMybF9omzjoLdtstTNvx0EOw3XZxRyZbKpvJItUEwl7s8TnAs+7eBDgJ+JeZbQMsBvZy93bAH4D/M7Mdi52Luz/p7nnuntdIq7KL5IwNG+Dee+GAA2DkyLD2xJgxcPDBcUcmZZXN3lALgD2THjdh82qmS4EuAO7+qZnVBRq6+7fAumj/ODObA+wL5GcxXhEpB6NHh7ETkyaFNSgefhj22ivuqGRrZbNkMRZoaWbNzaw20B0YVuyYr4FjAcysFVAXWGpmjaIGcsxsb6AlMDeLsYrIVvr+e7jqKjjsMPjuuzBu4vXXlSiqiqyVLNy9wMx6Au8ANYCB7j7VzPoA+e4+DPgj8JSZ3UCoorrI3d3MjgT6mFkBUAhc4e7LsxWriJSdOwweHGaI/fZbuO466NNHA+yqGnMv3oxQOeXl5Xl+vmqpRCrSl1+G0sTbb0P79vDkk6FbrFQeZjbO3fPSHafpPkRki23YAPfcExqwP/4YHngg9HRSoqi6NN2HiGyRTz+FHj3ClB3duoWusE2axB2VZJtKFiKSkcWLQy+nww4Lo7Fffx1efVWJorpQshCRUi1aFBqt994bnn4a/vAHmDYtdIuV6kPVUCKS0sKF0K9fmEK8oAB+97swt1OLFnFHJnFQshCRTSxYUJQkNm6ECy+EW24JJQupvpQsRASAr78OSeLpp0OSuPjisChR8+ZxRya5QMlCpJr76iu4+24YODA8vuSSkCSaNo03LsktShYi1dS8eXDXXfDss2AGl10GN92k6TkkNSULkWpm7tyQJAYNgm22CWMmevWCPfdMf65UX0oWItXE3Llw550hSdSsCVdeGZKEFiGSTChZiFRxK1aEif0eeSQkiauvDklijz3ijkwqEyULkSqqoACeeAJuuy1MH3755XD77bD77nFHJpWRkoVIFfTuu3DDDWGk9dFHh4n+fvnLuKOSykzTfYhUITNmwCmnQOfOsG4dvPYajBihRCFbT8lCpApYvjwsPtSmDXz0UVj/eupU6No1dIsV2VqqhhKpxFK1S/TpA7vsEndkUtWoZCFSSb3zDvzqV9CzZ7gfPx4ef1yJQrJDyUKkkpkxA04+Gbp0UbuEVBwlC5FKIrld4uOP1S4hFSujZGFmr5jZyWam5CJSwVavhgcfhJYt4eGH4dJLYdYsuPFGqFMn7uikusj04v8YcC4wy8z6mdn+WYxJRICZM8MKdY0bhxJF27Zql5D4ZNQbyt3fA94zs3rAOcBwM5sPPAX82903ZDFGkWqjsBDefBMefTQMrKtVC3772zBFR8eOqm6S+GTcddbMdgbOBy4AxgPPA78GLgSOykZwItXFd9+FRYf69w/rSzRuDH/7W5g2fNdd445OJMNkYWavAvsD/wJOdffF0VMvmVl+toITqerGjQuliBdegLVr4aij4B//CI3WNTUKSnJIpl/HR9z9/VRPuHteOcYjUuWtWwdDhoRZYEePhu23D0uYXnUVHHhg3NGJpJZpA3crM9sp8cDM6pvZVVmKSaRKWrAAevcOK9Gdf37oCvvgg7BwYah+UqKQXJZpsrjc3b9PPHD3FcDl2QlJpOpwhw8/hDPPhGbNwgp1hxwSRl9Pnw7XXgv16sUdpUh6mVZDbWNm5u4OYGY1gNrZC0ukcnOHt94KK9N98gk0aAB//CNccQU0bx53dCJbLtNk8Q4w2MweBxy4Ang7a1GJVFIbN8LQoSFJjB8fqpweeQQuuQS23Tbu6ETKLtNk0Qv4PXAlYMC7wIBsBSVS2RQUhB5Nd98dqpdatoSBA+G886C2yuBSBWQ6KG8jYRT3Y9kNR6RyWbcOBg2Cfv3gyy/DvE0vvhjaKGrUiDs6kfKT6TiLlsDdQGugbmK/u++dpbhEctqPP8JTT8F994XeTB06hKVLTzkFttEMalIFZVoN9QxwO3A/cDRwMaE6SqRaWbkyDKK7/35YtiwMonv2WTj2WE3FIVVbpr+BtnX3EYC5+1fufgdwTPbCEskty5bBX/4CTZvCrbfCwQeHacI/+ACOO06JQqq+TEsWa6PpyWeZWU9gIaB5L6XK++absG7E44/DTz/Bb34Dt9wC7dvHHZlIxco0WVwPbAdcC/QlVEVdmK2gRHLBggVhptclS+Ccc+Dmm6F167ijEolH2mQRDcA7293/BKwmtFeIVGmrV8Opp8KqVTB2LLRrF3dEIvFKmyzcvdDMDkoewS1SlRUWhvERkybBG28oUYhA5g3c44HXzewCM/tN4pbuJDPrYmYzzWy2md2U4vm9zOwDMxtvZpPM7KSk526OzptpZp0z/yeJbJ2bboJhw0JX2BNPjDsakdyQaZtFA+A7Nu0B5cCrJZ0QVV89ChwPLADGmtkwd5+WdFhvYLC7P2ZmrYH/As2i7e7AAcAehFX69nX3wgzjFSmTAQPC2ImrroKePeOORiR3ZDqCuyztFB2A2e4+F8DMXgS6AsnJwoEdo+16wKJouyvworuvA740s9nR631ahjhEMjJiBFx5JXTuHKYOV3dYkSKZjuB+hnBh34S7X1LKaY2B+UmPFwAdix1zB/CumV0DbA8cl3Tu6GLnNk4RVw+gB8Bee+1V6r9BpDQzZoQpOvbdF156SavUiRSXaZvFG8Cb0W0EoTSwOs05qX6XFU845wDPunsT4CTgX9F4jkzOxd2fdPc8d89r1KhRmnBEUlu2LEzTUatWaNDW+hIim8u0GuqV5Mdm9gLwXprTFgB7Jj1uQlE1U8KlQJfoPT41s7pAwwzPFdlq69aFgXYLFoTR2FprQiS1sk551hJIV+8zFmhpZs3NrDahwXpYsWO+Bo4FMLNWhEkKl0bHdTezOmbWPHq/MWWMVSQld+jRAz76CJ55Bg49NO6IRHJXpm0Wq9i0GugbwhoXJXL3gmhqkHeAGsBAd59qZn2AfHcfBvwReMrMbohe/6JoLMdUMxtMaAwvAK5WTygpb/36wXPPwR13hBHaIlIyqyrj7PLy8jw/Pz/uMKSSGDIEzjorJInnn1fPJ6m+zGycu+elOy6jaigz62Zm9ZIe72Rmp29NgCJxGTsWLrggVDsNHKhEIZKJTNssbnf3lYkH7v49YX0LkUrl66/htNNgt93gtdegbt3054hI5iO4UyUV9USXSmXVqjA54Jo18N57sIsm2RfJWKYli3wz+6eZtTCzvc3sfmBcNgMTKU+FhaF9YupUGDwYDjgg7ohEKpdMk8U1wHrgJWAw8BNwdbaCEilvf/oTvPkmPPRQmM5DRLZMpoPyfgQ2mzVWpDJ44omwZva114YJAiUD7vDddzB79qa3RYvCwuMXXKARjNVMRl1nzWw4cFbUsI2Z1SdM9Jczv9HUdVZSGT48TDPeuXOYdrxGjbgjyiHuYd3YOXM2TwqzZ8PKlUXHmsFee0GDBjBhQjj3yCPhd78Lk2ppjpRKK9Ous5k2UjdMJAoAd19hZmoelJw2fXoYS9G6Nbz4YhVMFO6wYUNYHHzt2nBf2u3HH+Grr4qSwZw5YV9CjRrQrBnssw8ccki4T9yaN4c6dcJxX38N//43DBoEl10W5nLv1i0kjuOO0yyMVVSmJYtxQDd3/zp63Ax41d1zZtl6lSwk2VtvhZqSmjXhs8+gadO4I9pCS5fC5MlFt6lTYfnyzRPAxo1b9rq1a8Pee4cE0KLFpgmhadMwm2Km3GHMmDAM/oUXYMWK0Cf5vPPgwguhTZsti01ikWnJItNk0QV4EvhftOtIoIe7v7NVUZYjJQsBKCiAv/wlTOXxy1/Cyy+Hacdz1po1IREkJ4bJk+Hbb4uOadgQDjww9PXddtuy37bbDho1yk4Ra906+O9/Q2njzTfDH6Jt21DaOPdc2HXX8nsv99C9TSWYclGuySJ6wV0Ia0dMIEz49627f7hVUZYjJQtZuBC6d4ePPw4TBD7wQLhG5oTCwlD1UzwpzJkTLn4Qgj3ggPCLvE2bkCDatAkX2so0zHzZslDvN2gQ5OeH5NSlS0gcp52WeiRkYWFoUP/223BbsqT0+7VrYb/9wgLp7duH+3btQpuKbJHyLllcBlxHmCp8AnAI8Km7H1PqiRVIyaJ6e/vtUO3000+h99N558Uc0Nq18MknYfTf++/DxIlhH8A220DLlkXJIHHbe++q17AybRr861/htnBhaAg/9dRQfZacAJYtS12lVqNGKFHtuuum93XqwJQp8PnnYX75hKZNN00g7dvD7rtvXbL96afQ1jNvXrhP3l6zJiSt/fcPt1atQlE2Z36lpFfeyWIycDAw2t3bmtn+wF/d/bdbH2r5ULKongoK4Pbb4a67wvX25ZfD/90KV1gYLlwjRoQEMWpUSA41a0LHjqHBOJEUWrWqVBeTclFYGBYMee45eOcd2GGHcNFPlQiS73faKSTX0ixdCuPHF90+/xxmzSp6fpddNi19tG8fEnMigaxalToRJO6TqwQh/E332iskprp14Ysv4Msvi5KdWegokEgeyYmkYcPy+TzLUXkni7HufrCZTQA6uvs6M5vg7m3LI9jyoGRR/SxaFEZlf/hh6JTz4IOhWr5CuIeLxHvvhQTxwQfwfdRhsE2b0Cvo2GND99IddqigoORnq1aF0tznnxclkGnTwq8LgB13DBf8hQtDw3yyOnVCImjaNFz0i9/vvvvmJcC1a0OCmj49rNGbuJ85M5RMEnbeefMEcuCBsOeesVU1lneyGApcDFwPHAOsAGq5+0lbG2h5UbKoXt59F84/P/T8fOKJsJ11ixYVlRxGjAgXGggXkGOPDQnimGM06VSuWrs2dCZIJJAFC6BJk80Twi67pC/NZGrjxtDVODmBJO6XLi06bpddoEOHotvBB1dY+0u5N3AnvXAnoB7wtruvL2N85U7JonooKAiLFd11V2gLHjw4/DjLmpEj4ZVXQoKYMSPsa9gwJIVEgth77ywGIFXWd9+FxDFpUuiCPGZM+I4lrsn77LNpAmnbNivVl1lLFrlKyaLqW7Qo9ML83//gkkvg4YezWO00fjz06hWGgG+3HXTqFJLDsceGPrnl9ctTJNnKlTBuXFHyGDOmqARbs2ao4kxOIK1abXWnCCULqVKGDw89nH78ER57LPTCzIqvvoLevcMI5QYNwvaVV2rhC4nPokVhxa5E8hg7tmgqlu23h7y8UMLt3btML1/e032IxKKwEP76V/jb38KPqJEjw/Qd5W75crjzTnjkkVBquOmmULLYaacsvJnIFthjD+jaNdwgtIPMmrVp6WPs2KyHoWQhOWvx4lDtNHJkmD3i0UfDD6ly9dNPoT7r7rvhhx/CG/XpExo+RXLRNtuE/uH77RcGF0FRO0c23zbr7yCyhZYvD2tjt2sX5nV65hl49tlyThSFheFF9903lCAOPzx0tRw4UIlCKp8K6HarkoXkhPnz4fXXYejQ0IBdWBi6n48YUc6r2rmH4d69eoXpNg4+OLRPdOpUjm8iUvUoWUhspk8PyWHo0DCFEIR2iV69wozXBx1Uzj+Y8vPhz38OA+hatICXXgpzmFemeZdEYqJkIRVm48bQDvfaayFBzJwZ9nfoEJoMunXL0lQdc+bArbeG5NCoUWij6NEjTNctIhlRspCs2rAhVCsNHRqqmRYuDN3FjzoqLHPatSs0bpylN1+6NHSjeuyxsE5D795hMe4dd8zSG4pUXUoWUm4KCsL0SCtWhAlBhw6FN94Ij7fdNsxS3a0bnHIK1K+fxUCWLIH77gtJYu1auPTSMOx7992z+KYiVZuShWxm5crQI2n58nChX7Gi5O3kxz/8sOnrNGgQli/o1g2OP74CJvlbtAjuvTdMFrVuXZhlsHfvMGGbiGwVJQvBPXQMeuWVcJs6teRja9cOSaB+/XDfuHHotZS8r379MKHnYYdV0GJm8+fDPffAgAGheHPBBXDLLWHNCBEpF0oW1ZR7aGx+5RV49dWwiJsZHHFEmKRvt902TwD164fqpJzpPDRvXlg/deDA8A+6+OIw8loT+4mUOyWLaqSwMKzJ8+qr4TZ/fvjlf8wxcOONcPrp5btUctbMmRMy2nPPhdGsl10W+ts2bRp3ZCJVlpJFFbdhQ9Es26+9Ftp+69SBE06Avn3DCpeVZtnimTNDknj++dC76corw7gJjbgWyToliypo7dowS+srr8CwYaHxefvt4aST4Iwzwn3KxduWLg2NF0uWhLn099svN7qZTpsWusC+9FLIdNddF4pC6t0kUmGULKqIJUvC6nFvvhluq1dDvXqhN9IZZ4SSxM/rpqxZA/nTQmJIvi1ZsvkLN26cei3h3XfPfuPFpEkhSQwZErpS3Xgj/PGPWolOJAZKFpXU+vXwySfwzjvhNn582N+oUegx+pvfwDGdCqn99eyQCPpNDoMfJk8OrdmJWSrr1g2TL514YlhYpU2b0Lo9e3ZYtSuxDOSgQWFd44Qdd9w0eSS2W7QIVUSpAk70s02+pdq3fHlYRWzu3FAEuuUWuP76nFzsXqS60OJHlcicOUXJ4f33Q+mhZs3QRfWUo1ZzWuNxtPwhn22mRCWFadNCnRSEhuB99gnJ4MADixJDixaZrbTlHsYxJK8hnNhetKjouJo1w/vstlsYoZe4+K9eXfJrmxV1u0q+HXBAaJfI6gg+kepNK+VVAatXhznv3n47JIg5c8L+ls02cNFBkzmp0Vharx5D7QljQmLYuDEcsNtuRckgcWvdOivr9wJhNN7MmZsuSL906eYX/1S3+vVDfZmWKRWJhZJFJbRxY6imTySHUaNgwwbnwLpz+N3+Yzi+3hj2+2EMdaePxxIlhoYNi9bjPfjgsMSi6vRFJENaVrUS2bAB+vcPg5ALFy+hA2PovstYHm8yhr2XjaHWqhUwgdDIe9BBcNVVRQmiWbMcGiUnIlWVkkWM3OE//4E/3egcOmsQ+XX7sAdfhie/qwG7HwjHnVmUGFq3rqD5M0RENpXVK4+ZdQEeBGoAA9y9X7Hn7weOjh5uB+zi7jtFzxUCk6Pnvnb307IZa0WbMCH0Ap3//hc8t90VHMIHeNtD4OxrQnVSu3ZZWHBaRKRsspYszKwG8ChwPLAAGGtmw9x9WuIYd78h6fhrgHZJL/GTu7fNVnxxWbw4TIT674HruW3be+lVsy81atWFJ57ALrtMDb0ikpOyeWXqAMx297nuvh54EehayvHnAC9kMZ5YrVkTxpe1bAmzBn3CVzu359afelOz22nY9Olh5TYlChHJUdm8OjUG5ic9XhDt24yZNQWaA+8n7a5rZvlmNtrMTi/hvB7RMflLly4tr7jL1caNYSqj/faDe/+ykiG7XsX/Nv6a3bb7ITRYDB6saStEJOdlM1mk6qJTUj/d7sAQdy9M2rdX1J3rXOABM2ux2Yu5P+nuee6e16hRo62PuJx9/DEccgicf75zTu1X+HbnVnSZ9wR2/fVhXMQpp8QdoohIRrKZLBYAeyY9bgIsKuHY7hSrgnL3RdH9XGAkm7Zn5LS5c+Hss8PaEP71fL5udzp/n3smdfbcFT77DP75T/jFL+IOU0QkY9lMFmOBlmbW3MxqExLCsOIHmdl+QH3g06R99c2sTrTdEDgcmFb83FyzcmWYMbtVK3jrjULeOvEhxvzYmj1nvheW+xw7NgyaExGpZLLWG8rdC8ysJ/AOoevsQHefamZ9gHx3TySOc4AXfdOh5K2AJ8xsIyGh9UvuRZVr3OGpp+DWW8P8d71PnUjvry+n9ltjoUuXMOKuefO4wxQRKTNN91EOhg2Drl3hhF+vYVCLPuz27/vCvEcPPgjdu2uEtYjkLE33UUHcoU8fuGC34Qxa+Hvs4y/h0kvh73+vREvQiYiUTsliK731Fvi4cQyyzljLlmEN006d4g5LRKRcKVlshUSp4qbtHwG2gzFjwnTbIiJVjIYMb4X33oNZn31Ht/UvYhdcoEQhIlWWkkUZucNf/wrX7fgsNTesDSu6iYhUUaqGKqORI+GTURt5o9HjcPjh8Mtfxh2SiEjWqGRRRn37wtn132OnpbPDYkQiIlWYShZl8PHHYW3sWQf2h5qN4Iwz4g5JRCSrVLIog759od3OX9Ni2n/gssugTp24QxIRySoliy00ejS8+y488qunMPewDoWISBWnZLGF+vaF3RoN0218AAARUUlEQVSs55ApT8HJJ0OzZnGHJCKSdUoWW2DcOPjvf6H/8UPZ5tslatgWkWpDyWIL9O0LO+0Epy6IZpHt3DnukEREKoSSRYYmToTXX4c7z51KzVEfwhVXaM1sEak2dLXL0N/+BjvuCJesfyz0frrkkrhDEhGpMEoWGZgyBYYMgT/2WEXdl54La6Y2bBh3WCIiFUbJIgN33gnbbw9/2PV5WLVKDdsiUu0oWaQxYwa89BL0vNr5xb8eg7ZtoWPHuMMSEalQShZp3HUX1K0LvY74BCZNCqUKLZMqItWMkkUpZs+G//u/MPt4/Rf6hxbuc8+NOywRkQqniQRLcffdUKsW/Pmib+Ggl0PW2H77uMMSEalwKlmUYN48eO45uPxy2PXNgbBhQxhbISJSDalkUYJ+/cKYuz//sRA6PQ5HHw2tWsUdlohILFSySGH+fBg4EC69FJpMfgu++krdZUWkWlPJIoV77glrbPfqBVzZH3bfHbp2jTssEZHYqGRRzKJFMGAAXHQRNC2cC2+/HRouatWKOzQRkdgoWRRz771QUAA33ww88URouLj88rjDEhGJlZJFkiVL4PHH4fzzYe891sLTT4fqpyZN4g5NRCRWShZJ/vEPWL8ebrkFePll+O47NWyLiKAG7p8tWwb9+0P37rDvvsBFj4WNY46JOzQRkdipZBG5/35YswZuvRUYPx4+/TSM2NY8UCIiKlkALF8ODz8MZ50FrVsDPR6DbbeFCy+MOzQRkZygkgXw4INhmYrevYGVK+H558OEgfXrxx2aiEhOqPbJYuXKkCy6dYM2bQgTQq1ZE6qgREQEUDUU69bBGWfA1VcThm337w8dOsBBB8UdmohIzqj2yWKXXcJwCgA+GBmWxnv22RgjEhHJPdW+GmoT/ftDgwZw9tlxRyIiklOULBIWLYLXXoOLLw49oURE5GdZTRZm1sXMZprZbDO7KcXz95vZhOj2hZl9n/TchWY2K7plvw/rgAFhUigtcCQispmstVmYWQ3gUeB4YAEw1syGufu0xDHufkPS8dcA7aLtBsDtQB7gwLjo3BVZCXbDhjBpYOfOsM8+WXkLEZHKLJsliw7AbHef6+7rgReB0haFOAd4IdruDAx39+VRghgOdMlapP/5T6iG0jxQIiIpZTNZNAbmJz1eEO3bjJk1BZoD72/pueXiscdgr73g5JOz9hYiIpVZNpNFqkmVvIRjuwND3L1wS841sx5mlm9m+UuXLi1blLNnw3vvQY8eUKNG2V5DRKSKy2ayWADsmfS4CbCohGO7U1QFlfG57v6ku+e5e16jRo3KFmWLFjBypBY4EhEpRTaTxVigpZk1N7PahIQwrPhBZrYfUB/4NGn3O8AJZlbfzOoDJ0T7yp8ZdOoURueJiEhKWesN5e4FZtaTcJGvAQx096lm1gfId/dE4jgHeNHdPenc5WbWl5BwAPq4+/JsxSoiIqWzpGt0pZaXl+f5+flxhyEiUqmY2Th3z0t3nEZwi4hIWkoWIiKSlpKFiIikpWQhIiJpKVmIiEhaVaY3lJktBb7K4ls0BJZl8fXLS2WJEypPrIqzfFWWOKHyxLo1cTZ197SjmqtMssg2M8vPpHtZ3CpLnFB5YlWc5auyxAmVJ9aKiFPVUCIikpaShYiIpKVkkbkn4w4gQ5UlTqg8sSrO8lVZ4oTKE2vW41SbhYiIpKWShYiIpKVkISIiaSlZJDGzPc3sAzObbmZTzey6FMccZWYrzWxCdLstpljnmdnkKIbNptu14CEzm21mk8ysfQwx7pf0OU0wsx/M7Ppix8T2eZrZQDP71symJO1rYGbDzWxWdF+/hHMvjI6ZZWYXxhDnvWY2I/rbDjWznUo4t9TvSQXEeYeZLUz6+55UwrldzGxm9H29KZtxlhLrS0lxzjOzCSWcW5GfacprUizfU3fXLboBuwPto+0dgC+A1sWOOQp4IwdinQc0LOX5k4C3CEvUHgJ8FnO8NYBvCAOAcuLzBI4E2gNTkvb9Hbgp2r4JuCfFeQ2AudF9/Wi7fgXHeQJQM9q+J1WcmXxPKiDOO4AbM/huzAH2BmoDE4v/v6uIWIs9/w/gthz4TFNek+L4nqpkkcTdF7v759H2KmA60DjeqMqsK/CcB6OBncxs9xjjORaY4+7ZHGW/Rdz9Q6D4olpdgUHR9iDg9BSndgaGu/tyd18BDAe6VGSc7v6uuxdED0cTlh6OVQmfZyY6ALPdfa67rwdeJPwdsqa0WM3MgLPZdKnnWJRyTarw76mSRQnMrBnQDvgsxdOHmtlEM3vLzA6o0MCKOPCumY0zsx4pnm8MzE96vIB4E1/xddaT5cLnmbCruy+G8B8VSLXebq59tpcQSpGppPueVISeUXXZwBKqS3Lt8zwCWOLus0p4PpbPtNg1qcK/p0oWKZjZL4BXgOvd/YdiT39OqEr5FfAw8FpFxxc53N3bAycCV5vZkcWetxTnxNJP2sIa7KcBL6d4Olc+zy2RS5/trUAB8HwJh6T7nmTbY0ALoC2wmFC9U1zOfJ6Rcyi9VFHhn2maa1KJp6XYV+bPVcmiGDOrRfijPO/urxZ/3t1/cPfV0fZ/gVpm1rCCw8TdF0X33wJDCUX5ZAuAPZMeNwEWVUx0mzkR+NzdlxR/Ilc+zyRLEtV10f23KY7Jic82arA8BTjPo0rq4jL4nmSVuy9x90J33wg8VcL758TnCWBmNYHfAC+VdExFf6YlXJMq/HuqZJEkqqt8Gpju7v8s4ZjdouMwsw6Ez/C7iosSzGx7M9shsU1o7JxS7LBhwO+iXlGHACsTxdYYlPhLLRc+z2KGAYleIxcCr6c45h3gBDOrH1WrnBDtqzBm1gXoBZzm7mtKOCaT70lWFWsn61bC+48FWppZ86gU2p3wd4jDccAMd1+Q6smK/kxLuSZV/Pe0Ilr0K8sN+DWhmDYJmBDdTgKuAK6IjukJTCX02BgNHBZDnHtH7z8xiuXWaH9ynAY8SuhlMhnIi+kz3Y5w8a+XtC8nPk9CAlsMbCD8CrsU2BkYAcyK7htEx+YBA5LOvQSYHd0ujiHO2YT66MT39PHo2D2A/5b2PangOP8Vff8mES5wuxePM3p8EqGnz5xsx1lSrNH+ZxPfzaRj4/xMS7omVfj3VNN9iIhIWqqGEhGRtJQsREQkLSULERFJS8lCRETSUrIQEZG0lCxERCQtJQsREUlLyUKkgkXrIZRpShMzu8jM9iiP1xLZEkoWIpXLRYQRxSIVSslCqi0zaxatNjfAzKaY2fNmdpyZjYpWFusQ3T4xs/HR/X7RuX8ws4HRdpvo/O1KeJ+dzezd6DWeIGk2UDM738zGRKuuPWFmNaL9q83sH2b2uZmNMLNGZnYmYTqH56Pjt41e5prouMlmtn82PzOpvpQspLrbB3gQ+CWwP3AuYT6eG4FbgBnAke7eDrgNuCs67wFgHzPrBjwD/N5LmNAPuB34OHqNYcBeAGbWCvgtYcrrtkAhcF50zvaEmXrbA/8Dbnf3IUA+YZbZtu7+U3Tssui4x6K4RcpdzbgDEInZl+4+GcDMpgIj3N3NbDLQDKgHDDKzloQJ3WoBuPtGM7uIMMHbE+4+qpT3OJIw7TXu/qaZrYj2HwscBIyNJt7dlqKppjdSNE32v4HNpstPknhuXOJ9RMqbkoVUd+uStjcmPd5I+P/RF/jA3btFK5WNTDq+JbCazNoQUs3YacAgd7+5jOcnJGIuRP+nJUtUDSVSunrAwmj7osROM6tHqL46Etg5ak8oyYdE1UtmdiKQWFp0BHCmme0SPdfAzJpGz20DJF7zXODjaHsVsMNW/HtEykTJQqR0fwfuNrNRQI2k/fcD/d39C8K6Df0SF/0U/gocaWafExag+RrA3acBvQnrOU8ChgOJxYJ+BA4ws3HAMUCfaP+zwOPFGrhFsk7rWYjkIDNb7e6/iDsOkQSVLEREJC2VLETKiZldDFxXbPcod786jnhEypOShYiIpKVqKMHMCqMG04nRSODDov3NzGxKDPE0M7Nzy3juJxkcM8DMWpfl9SuSmd1hZgujv800MzunDK+xuhziOL2sn5eZtTWzk7Y2BomfkoUA/BSNCP4VcDNwd8zxNCN0F92MmZU6jsDdD0v34u5+WdQTqTK4Pxrd3RV4wsxqxRDD6UBZk2tbQMmiClCykOJ2BFYU3xnNdvpI0uM3zOyoaPsEM/s0KpW8bGZb24unH3BE9Iv6hui9Xzaz/xC6mf4imi8pMR9S16S4Vkf3R5nZSDMbEs3/9LxFw6Sj/XmJ483szqhUNdrMdo32t4gejzWzPiX9Qjez18xsnJlNNbMeSfu7RPFNNLMR0b5fmNkzUcyTzOyMTD8Qd58FrCEaoxHF93b03h8l5oQys+bR32KsmfXdkg+9hH/fYcBpwL3R36NFKe99loU5siaa2YdmVpvQ5fe30bm/LfbazaLzP08u0UbP/Tn6nCaaWb9o3z5m9l5SCbjF1v77ZAu4u27V/EYY+TuBMA/SSuCgaH8zYEq0fRHwSNI5bwBHAQ0Jg862j/b3Am5L8R5/it6j+O2hFMceBbyR9PgiYAHQIHpcE9gx2m4IzKao/W110musBJoQfhR9Cvw6em4kkBdtO3BqtP13oHfSv++caPuKxOumiDUR07bAFGBnoBEwH2he7Jh7gAeSzq2f5u9yB3BjtN0e+CjpuRFAy2i7I/B+tD0M+F20fXUpcX9Uwt/juBTHPgucmcF7TwYaR9s7pfreFHvd7YC60XZLID/aPhH4BNiu2Of3GdAt2q6beF63irlpagCBqBoKwMwOBZ4zswMzPPcQQhXFqOiHe23ChXkT7n4vcO9WxDjc3ZdH2wbcZWZHEqblaAzsCnxT7Jwx7r4AwMwmEJLfx8WOWU9IDBDmVjo+2j6UUP0C8H/AfSXEda2FyQQB9iRc9BoBH7r7lwBJcR8HdE+c6O6bleBSuMHMLgf2BrpE/5ZfAIcBL0efOUCd6P5wIFFi+RchQW3G3Y/I4L03k+a9RwHPmtlgSp/LKqEW8IiZJSZR3DfafxzwjEcTM7r7cjPbgZCIhkb71pYlfik7JQvZhLt/amExnUbFnipg02rLutG9ES7kpTa+mtmfKJpRNdmH7n5tBqH9mLR9XhTfQe6+wczmJcWTLHnep5LmTdrg0U/VUo5JKaqGOw441N3XmNnIKA6j5LmgtrT74f3ufp+Z/YaQxFsQ/g7fJxJ8Cmnfw8w+IvW0ITe6+3ulnFrie7v7FWbWETgZmBAlgdLcACwBfhW9biIBpPqcDImV2ixkE1H9cw3gu2JPzQPamtk2ZrYn0CHaPxo43Mz2ic7fzsz2LXYu7n6vh0b04rdUiSLd/Ef1gG+jRHE00LSUY8tqNEW/0LuXcEw9YEWUKPYnlLIglKw6mVlzCHM+RfvfBXomTjaz+mTI3V8lTE9+obv/AHxpZmdFr2Nm9qvo0FFJ8aZKzonXO6KEv0eqRPHz36O09zazFu7+mbvfBiwjlLRK+1vWAxa7+0bgAoqmU3kXuMSi9UHMrEH0vgvM7PRoXx0rYf0QyQ4lCwHYNmqAnECYFvtCdy8sdswo4EtCvfR9wOcA7r6UUC/9goX5jUYT1oXYGpOAgqgh84YUzz8P5JlZPuGCOGMr3y+V64E/mNkYwnxNK1Mc8zZQM/p39yX82xOfSQ/gVTObSNFU438D6icagYGj4eeuvHkZxNQnimkbwr/70uh1phJ6S0EYFHi1mY0lXIzLw4vAnyws3tSilPe+N2qUnkJox5oIfAC0TtXADfQHLjSz0YQqqB8B3P1tQttLfvSdTKzRcQGh2m8SoU1jN/i5ilGyTIPyRFKIfrX+5O5uZt0Jjd1d050nUlWpzUIktYMIja8GfA9cEnM8IrFSyUJERNJSm4WIiKSlZCEiImkpWYiISFpKFiIikpaShYiIpPX/L72AnKiXO9sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_score = []\n",
    "train_score = []\n",
    "\n",
    "# check the model performance for max depth from 2-20\n",
    "for max_depth in range(2, 21):\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, random_state=rs)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_score.append(model.score(X_test, y_test))\n",
    "    train_score.append(model.score(X_train, y_train))\n",
    "    \n",
    "# plot max depth hyperparameter values vs training and test accuracy score\n",
    "plt.plot(range(2, 21), train_score, 'b', range(2,21), test_score, 'r')\n",
    "plt.xlabel('max_depth\\nBlue = training acc. Red = test acc.')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7648781786712822\n",
      "Test accuracy: 0.7555141348244796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      1609\n",
      "           1       0.80      0.68      0.73      1610\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      3219\n",
      "   macro avg       0.76      0.76      0.75      3219\n",
      "weighted avg       0.76      0.76      0.75      3219\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 30}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': range(3, 9),\n",
    "          'min_samples_leaf': range(20, 80, 10)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "# test the best model\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7648781786712822\n",
      "Test accuracy: 0.7555141348244796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      1609\n",
      "           1       0.80      0.68      0.73      1610\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      3219\n",
      "   macro avg       0.76      0.76      0.75      3219\n",
      "weighted avg       0.76      0.76      0.75      3219\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 26}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV #2\n",
    "params = {'criterion': ['gini'],\n",
    "          'max_depth': range(4, 9),\n",
    "          'min_samples_leaf': range(20, 35)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "# test the best model\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*********** Evaluation of the decision tree ************\n",
      "\n",
      "Train accuracy: 0.7638130741579018\n",
      "Test accuracy: 0.7601739670705188\n",
      "\n",
      "\n",
      "*********** Confusion Matrix ************\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78      1609\n",
      "           1       0.81      0.68      0.74      1610\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      3219\n",
      "   macro avg       0.77      0.76      0.76      3219\n",
      "weighted avg       0.77      0.76      0.76      3219\n",
      "\n",
      "\n",
      "\n",
      "*********** Feature Importances ************\n",
      "\n",
      "Auction_ADESA                      :0.5422671171500951\n",
      "MMRCurrentAuctionAveragePrice      :0.13801354497205165\n",
      "VNST_OK                            :0.08723228534468135\n",
      "VNST_CO                            :0.04921416972858956\n",
      "VNST_AZ                            :0.030766798824604577\n",
      "VNST_PA                            :0.027641810115690942\n",
      "Auction_OTHER                      :0.026026203246378853\n",
      "VNST_MO                            :0.025090514534735073\n",
      "VehBCost                           :0.02446775272462682\n",
      "VNST_CA                            :0.014623701419056629\n",
      "VNST_NC                            :0.01254757997967377\n",
      "VNST_FL                            :0.006523228827706428\n",
      "MMRCurrentRetailRatio              :0.0062168351504326745\n",
      "VNST_TX                            :0.004481788953987272\n",
      "MMRAcquisitionAuctionAveragePrice  :0.003104321403774169\n",
      "MMRCurrentRetailAveragePrice       :0.0017823476239150367\n",
      "Make_MERCURY                       :0.0\n",
      "Make_MAZDA                         :0.0\n",
      "Make_LINCOLN                       :0.0\n",
      "VNST_WV                            :0.0\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "The binary tree structure has 35 nodes and has the following tree structure:\n",
      "The tree has 17 decision nodes.\n",
      "The tree has 18 leaf nodes.\n",
      "\n",
      "\n",
      "*********** Size of optimal decision tree on test set ************\n",
      "\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "The binary tree structure has 39 nodes and has the following tree structure:\n",
      "The tree has 19 decision nodes.\n",
      "The tree has 20 leaf nodes.\n"
     ]
    }
   ],
   "source": [
    "# Assigining the best parameter to optimal model\n",
    "Optimal_model = DecisionTreeClassifier(criterion = 'gini', splitter = 'best', max_depth = 6,  min_samples_leaf = 26)\n",
    "\n",
    "Optimal_model.fit(X_train, y_train)\n",
    "\n",
    "# decision tree evaluation\n",
    "print(\"\\n\\n*********** Evaluation of the decision tree ************\\n\") \n",
    "print(\"Train accuracy:\", Optimal_model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", Optimal_model.score(X_test, y_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n\\n*********** Confusion Matrix ************\\n\") \n",
    "y_pred = Optimal_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "analyse_feature_importance(Optimal_model, X.columns, 20)\n",
    "\n",
    "#visualising the model\n",
    "visualize_decision_tree(Optimal_model, X.columns, \"Optimal_model.png\")\n",
    "\n",
    "#Size of decision tree model\n",
    "size_of_tree(Optimal_model)\n",
    "\n",
    "\n",
    "#**************Fit model in test set*******************\n",
    "Optimal_model.fit(X_test,y_test)\n",
    "#visualising the model\n",
    "visualize_decision_tree(Optimal_model, X.columns, \"Optimal_model_val_data.png\")\n",
    "\n",
    "#Size of decision tree model\n",
    "print(\"\\n\\n*********** Size of optimal decision tree on test set ************\\n\") \n",
    "size_of_tree(Optimal_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of decison tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary tree structure has 35 nodes and has the following tree structure:\n",
      "node=0 test node: go to node 1 if X[:, 13] <= 0.5 else to node 34.\n",
      "\tnode=1 test node: go to node 2 if X[:, 6] <= 4738.0 else to node 25.\n",
      "\t\tnode=2 test node: go to node 3 if X[:, 97] <= 0.5 else to node 16.\n",
      "\t\t\tnode=3 test node: go to node 4 if X[:, 11] <= 4240.0 else to node 11.\n",
      "\t\t\t\tnode=4 test node: go to node 5 if X[:, 120] <= 0.5 else to node 8.\n",
      "\t\t\t\t\tnode=5 test node: go to node 6 if X[:, 98] <= 0.5 else to node 7.\n",
      "\t\t\t\t\t\tnode=6 leaf node.\n",
      "\t\t\t\t\t\tnode=7 leaf node.\n",
      "\t\t\t\t\tnode=8 test node: go to node 9 if X[:, 2] <= 3358.0 else to node 10.\n",
      "\t\t\t\t\t\tnode=9 leaf node.\n",
      "\t\t\t\t\t\tnode=10 leaf node.\n",
      "\t\t\t\tnode=11 test node: go to node 12 if X[:, 96] <= 0.5 else to node 15.\n",
      "\t\t\t\t\tnode=12 test node: go to node 13 if X[:, 107] <= 0.5 else to node 14.\n",
      "\t\t\t\t\t\tnode=13 leaf node.\n",
      "\t\t\t\t\t\tnode=14 leaf node.\n",
      "\t\t\t\t\tnode=15 leaf node.\n",
      "\t\t\tnode=16 test node: go to node 17 if X[:, 15] <= 0.5 else to node 24.\n",
      "\t\t\t\tnode=17 test node: go to node 18 if X[:, 10] <= 0.8278218507766724 else to node 21.\n",
      "\t\t\t\t\tnode=18 test node: go to node 19 if X[:, 8] <= 5535.5 else to node 20.\n",
      "\t\t\t\t\t\tnode=19 leaf node.\n",
      "\t\t\t\t\t\tnode=20 leaf node.\n",
      "\t\t\t\t\tnode=21 test node: go to node 22 if X[:, 10] <= 0.8855109214782715 else to node 23.\n",
      "\t\t\t\t\t\tnode=22 leaf node.\n",
      "\t\t\t\t\t\tnode=23 leaf node.\n",
      "\t\t\t\tnode=24 leaf node.\n",
      "\t\tnode=25 test node: go to node 26 if X[:, 115] <= 0.5 else to node 33.\n",
      "\t\t\tnode=26 test node: go to node 27 if X[:, 95] <= 0.5 else to node 32.\n",
      "\t\t\t\tnode=27 test node: go to node 28 if X[:, 117] <= 0.5 else to node 31.\n",
      "\t\t\t\t\tnode=28 test node: go to node 29 if X[:, 105] <= 0.5 else to node 30.\n",
      "\t\t\t\t\t\tnode=29 leaf node.\n",
      "\t\t\t\t\t\tnode=30 leaf node.\n",
      "\t\t\t\t\tnode=31 leaf node.\n",
      "\t\t\t\tnode=32 leaf node.\n",
      "\t\t\tnode=33 leaf node.\n",
      "\tnode=34 leaf node.\n",
      "\n",
      "Rules used to predict sample 0: \n",
      "decision id node 0 : (X_test[0, 13] (= 0.0) <= 0.5)\n",
      "decision id node 1 : (X_test[0, 6] (= 8260.0) > 4738.0)\n",
      "decision id node 25 : (X_test[0, 115] (= 0.0) <= 0.5)\n",
      "decision id node 26 : (X_test[0, 95] (= 0.0) <= 0.5)\n",
      "decision id node 27 : (X_test[0, 117] (= 0.0) <= 0.5)\n",
      "decision id node 28 : (X_test[0, 105] (= 0.0) <= 0.5)\n",
      "\n",
      "The following samples [0, 1] share the node [ 0  1 25 26 27 28 29] in the tree\n",
      "It is 20.0 % of all nodes.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*********** Size of decision tree ************\n",
      "\n",
      "The binary tree structure has 35 nodes and has the following tree structure:\n",
      "The tree has 17 decision nodes.\n",
      "The tree has 18 leaf nodes.\n"
     ]
    }
   ],
   "source": [
    "# The decision estimator has an attribute called tree_  which stores the entire\n",
    "# tree structure and allows access to low level attributes. The binary tree\n",
    "# tree_ is represented as a number of parallel arrays. The i-th element of each\n",
    "# array holds information about the node `i`. Node 0 is the tree's root. NOTE:\n",
    "# Some of the arrays only apply to either leaves or split nodes, resp. In this\n",
    "# case the values of nodes of the other type are arbitrary!\n",
    "#\n",
    "# Among those arrays, we have:\n",
    "#   - left_child, id of the left child of the node\n",
    "#   - right_child, id of the right child of the node\n",
    "#   - feature, feature used for splitting the node\n",
    "#   - threshold, threshold value at the node\n",
    "#\n",
    "\n",
    "# Using those arrays, we can parse the tree structure:\n",
    "\n",
    "n_nodes = Optimal_model.tree_.node_count\n",
    "children_left = Optimal_model.tree_.children_left\n",
    "children_right = Optimal_model.tree_.children_right\n",
    "feature = Optimal_model.tree_.feature\n",
    "threshold = Optimal_model.tree_.threshold\n",
    "\n",
    "\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "while len(stack) > 0:\n",
    "    node_id, parent_depth = stack.pop()\n",
    "    node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "    if (children_left[node_id] != children_right[node_id]):\n",
    "        stack.append((children_left[node_id], parent_depth + 1))\n",
    "        stack.append((children_right[node_id], parent_depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\"The binary tree structure has %s nodes and has \"\n",
    "      \"the following tree structure:\"\n",
    "      % n_nodes)\n",
    "\n",
    "# Calculate decision node\n",
    "decision_node_number = 0\n",
    "leaf_node_number = 0\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        leaf_node_number = leaf_node_number + 1\n",
    "        print(\"%snode=%s leaf node.\" % (node_depth[i] * \"\\t\", i))\n",
    "    else:\n",
    "        decision_node_number = decision_node_number + 1\n",
    "        print(\"%snode=%s test node: go to node %s if X[:, %s] <= %s else to \"\n",
    "              \"node %s.\"\n",
    "              % (node_depth[i] * \"\\t\",\n",
    "                 i,\n",
    "                 children_left[i],\n",
    "                 feature[i],\n",
    "                 threshold[i],\n",
    "                 children_right[i],\n",
    "                 ))\n",
    "print()\n",
    "\n",
    "    \n",
    "# First let's retrieve the decision path of each sample. The decision_path\n",
    "# method allows to retrieve the node indicator functions. A non zero element of\n",
    "# indicator matrix at the position (i, j) indicates that the sample i goes\n",
    "# through the node j.\n",
    "\n",
    "node_indicator = Optimal_model.decision_path(X_test)\n",
    "\n",
    "# Similarly, we can also have the leaves ids reached by each sample.\n",
    "\n",
    "leave_id = Optimal_model.apply(X_test)\n",
    "\n",
    "# Now, it's possible to get the tests that were used to predict a sample or\n",
    "# a group of samples. First, let's make it for the sample.\n",
    "\n",
    "sample_id = 0\n",
    "node_index = node_indicator.indices[node_indicator.indptr[sample_id]:\n",
    "                                    node_indicator.indptr[sample_id + 1]]\n",
    "\n",
    "print('Rules used to predict sample %s: ' % sample_id)\n",
    "for node_id in node_index:\n",
    "    if leave_id[sample_id] == node_id:\n",
    "        continue\n",
    "\n",
    "    if (X_test[sample_id, feature[node_id]] <= threshold[node_id]):\n",
    "        threshold_sign = \"<=\"\n",
    "    else:\n",
    "        threshold_sign = \">\"\n",
    "\n",
    "    print(\"decision id node %s : (X_test[%s, %s] (= %s) %s %s)\"\n",
    "          % (node_id,\n",
    "             sample_id,\n",
    "             feature[node_id],\n",
    "             X_test[sample_id, feature[node_id]],\n",
    "             threshold_sign,\n",
    "             threshold[node_id]))\n",
    "\n",
    "# For a group of samples, we have the following common node.\n",
    "sample_ids = [0, 1]\n",
    "common_nodes = (node_indicator.toarray()[sample_ids].sum(axis=0) ==\n",
    "                len(sample_ids))\n",
    "\n",
    "common_node_id = np.arange(n_nodes)[common_nodes]\n",
    "\n",
    "print(\"\\nThe following samples %s share the node %s in the tree\"\n",
    "      % (sample_ids, common_node_id))\n",
    "print(\"It is %s %% of all nodes.\" % (100 * len(common_node_id) / n_nodes,))\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"\\n\\n*********** Size of decision tree ************\\n\") \n",
    "print(\"The binary tree structure has %s nodes and has \" \"the following tree structure:\" % n_nodes)\n",
    "print(\"The tree has %s decision nodes.\" % decision_node_number)\n",
    "print(\"The tree has %s leaf nodes.\" % leaf_node_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
